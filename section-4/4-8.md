# Running Spark on a cluster

Packaging and deploying your application!

## Running with spark-submit

* Make sure there are no paths to your local filesystem used in your script! That's what HDFS, S3, etc are for!
    - We've been putting the relative paths
    - In real world, data is coming from distributed system
* Package up your scala project into a JAR file (using Export in the IDE)
* You can now use spark-submit to execute your drive script outside of the IDE
* sparksubmit --class <CLASS OBJECT THAT CONTAINS MAIN>
    - --jars <paths to any dependencies>
    - --files <files you want placed alongside application>
    - <YOUR JAR FILE>

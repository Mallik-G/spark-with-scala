# Item-based collaborative filtering

Finding similar movies using Spark and the MovieLens data set 

And introducing caching RDDs and persisting them! Something we need if we use RDDs more than once!

## Similar Movies

**Item based collaborative filtering!**

We try to find relationships between items - in this case movies based on customer behaviour

If we see 2 movies that users tend to rate together similarly, then maybe these movies might be similar.

And if one likes a movie, they might also like other "similar" movies that are connected through that behaviour data!

Movielens website has a recommender website!

e-commerce uses it as well!

## Overview

* Find every pair of movie that were watched by the same person
* Measure the similarity of their ratings across all users who watched both
* Sort by movie, then by similarity strength
* (This is just one way to do it)

### Example

* There is a lady that watched starwars 
    - and the empire strkes back
* Now we know the two movies were watched by the same person 
* There was another guy that watched those movies too
* By comparing behaviour of people that watch the same movies, might tell us that they watch similar movies
    - That might tell us that those movies are similar to each other
* But there might be another random guy that just comes in and watches the empire strikes back - so after you see it, they might tell you that given you watched X movie, you might also like Y!!

We like at people watching similar movies and rated them similarly.

It doesn't mean that they are good movies! But if both people recommended it as bad movies, that still joins the two movies, but it just joins them in a negative aspect

## Makign it a spark problem

* Map input ratings to (userID, (movieID, rating))
* Find every movie piar rated by the same user
    - This can be done with a self-join operation
    - At this point we have (userID, [(movieID1, rating1), ()........ ] )
* Filter out duplicate pairs
* Make the movie pairs the key
    - map to ((movieID1, movieID2...), (rating1, rating2),...)
* groupByKey() to get every rating pair found for each movie pair
* Compute similarity between ratings for each movie in the pair
* Sort, save, and display the results


## Caching RDDs

* In this example, we'll query the final RDD of movie similarities a couple of times
* Any time you will perfform more than one action of an RDD you must cache it!
    - Otherwise Spark might re-evaluate the entire RDD all over again
* Use .cache() or .persist() to do this
    - What is the difference?
    - Persist() optionally lets you cache it to disk instead of just memory, just in a case a node fails at something

 









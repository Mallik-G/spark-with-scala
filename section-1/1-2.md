# Create histogram of movie ratings

We're now going to take an exercise with movie ratings.

## Getting the data

Now let's go to [grouplens.org](https://grouplens.org) and download the movie-lens-100k data and download it!

You can download it with `wget http://files.grouplens.org/datasets/movielens/ml-100k.zip`

Let's unzip, and also download the following scala `wget http://media.sundog-soft.com/SparkScala/SparkScala.zip`

## Setting up IDE

* now in the IDE, we install SparkScalaCourse project.
* Then right click on it and say new package 
* We create a package called `yourdomainame.spark`
* Now we rightclick>import on the package. Then general, filesystem. We import the sparkscala folder in the downloads, and we should see a menu with resources for course. We'll go to ratingscounter.scala, and click finish.

That will give us the code under our package!

Right now we can't compile it as we have a few problems.

We can see the problems in the message below.

Right now we dont have anything to link against.

But we can right click on project > properties.

* Java Build Path
* Libraries
* Add external jars....
    - Now find the folder where we installed spark
        + ie. /usr/local/Cellar/apache-spark/2.1.1/
        + I copied it to the folder 
    - Select all and add

If you give it a few seconds, the errors should crlear up...

**Make sure that the version of scala used is the relevant one for the JARs...**

# Running

* Go to run configurations.
* Create scala application 
    - Call it RatingsCounter
    - Add the main class object:
        + yourdomain.spark.RatingsCounter

And now should work!

We run it, and the output is:

```
(1,6110)
(2,11370)
(3,27145)
(4,34174)
(5,21201)
```

(Sidenote: This dataset is going to 1998 by the way)

We've ran some real code using scala! We'll now go into more detail:

* We have an object that holds the top
* First thing is we remove some of the log span to only see errors
* Then we setup our spark context, 
    - and specify that we'll run it locally
* Then we load the text file into an RDD
* Parse the data using a lambda into a map splitting on tab character
* Finally we call the function countByValue
* And then we sort the results with sortBy _._1

Now we're gonna have a crashcourse on the Scala Language!






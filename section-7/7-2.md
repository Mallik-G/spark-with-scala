# Linear regression with MLLib

* Fit a line to a data set of observations
* Use this line to predict unobserved values
* I don't know why they call it "regression". It's really misleading. You can use it to predict points in the future, the past, whatever. In fact time usually has nothing to do with it.

## how does linear regression work?

* Usually using "least squares"
* Minimizes the squared-error between each point and a line
* Remember slope intercept eq. of a line is y=mx+b
* The slope is the correlation between the two variables, times the standard dev in Y, all divivded by the stdev in X

## There are more ways

* Spark streaming uses a more complex technique called stochastic gradient descent
* Friendlier to multi-dimensional data as it looks for contours in higher dimensions

## Linear regression with MLLib

* Set up your model look like this:

``` scala
val algorithm = new LinearRegressionWithSGD()

algorithm.optimizer
    .setNumIterations(100)
    .setStepSize(1.0)
    .setUpdated(new SquaredL2Updater())
    .setRegParam(0.01)
```

* You train the model and make predictions using labelledpoint objects 

## Gotchas with SGD linear regression

* SGD doesn't handle "feature scaling" well, It assumes your data is similar to a linear distribution
* So you need to scale your data down and back up again when you are done
* It also assumes that your y-intercept is 0, unless you call algorithm. setIntercept(true)

# Let's try it!

* We'll fabricate data for average page speed and revenue generated from session data on an online store
* Can we predict revenue based on a page speed using a linear model

## Code

There is a file called `regression.txt`. It has 2 columns, separated by commas. You can read it very simply. It has simulated page speeds. We had to normalize the data to fit in the normal distribution curve, and scale back up when done.

We have to import a set of specifc ML classes that we need to use.

```scala
import org.apache.spark._
import org.apache.spark.SparkContext._
import org.apache.spark.sql._
import org.apache.log4j._
import org.apache.spark.mllib.linalg.Vectors
import org.apache.spark.mllib.regression.LabeledPoint
import org.apache.spark.mllib.regression.LinearRegressionWithSGD
import org.apache.spark.mllib.optimization.SquaredL2Updater
```

With supervised techniques we are training an algoritm and applying to unknown data.

We will use the same data for training and testing:

``` scala
  val trainingLines = sc.textFile("../regression.txt")
    
    // And another RDD containing our "test" data that we want to predict values for using our linear model.
    // This will expect both the known label and the feature data. In the real world you won't know
    // the "correct" value and would just input feature data.
    val testingLines = sc.textFile("../regression.txt")
```

Now we get an rdd of value points


``` scala
    // Convert input data to LabeledPoints for MLLib
    val trainingData = trainingLines.map(LabeledPoint.parse).cache()
    val testData = testingLines.map(LabeledPoint.parse)
    
```

Then set the parameters and run it

``` scala

    val algorithm = new LinearRegressionWithSGD()
    algorithm.optimizer
      .setNumIterations(100)
      .setStepSize(1.0)
      .setUpdater(new SquaredL2Updater())
      .setRegParam(0.01)
      
      
    val model = algorithm.run(trainingData)
    
```

After we've trained it, now we want to predict page speeds just and make predictions of amount spent and compare to the previous original one.

``` scala

    // Predict values for our test feature data using our linear regression model
    val predictions = model.predict(testData.map(_.features))
    
    // Zip in the "real" values so we can compare them
    val predictionAndLabel = predictions.zip(testData.map(_.label))
 ```

 Finally we just print it all out

 ``` scala
    // Print out the predicted and actual values for each point
    for (prediction <- predictionAndLabel) {
      println(prediction)
    }
 ```




# Spark Structured Streaming (Way of future!)

* Spark 2.0 introduced structured streaming
* Uses DataSets as its primary APIs
* Imagine a dataset that just keeps growing appended to forever, and you query it whenever you want
    - val inputDF = spark.readStream.json("s3://logs")
    - inputDF.groupBy($"action", window($"time", "1 hour")).count()
        + .writeStream.format("jdbc").start("jdbc:mysql//...")

* We can specify which col we want to order by
* Instead of selecting which rdd is added, here you can say everything is in order
* You can use that and make window based on that and make sure everything gets processed in corrrect order
* keeps appending to db what comes in 
* Very simple API that belittles complexity in the background
* It takes continuous applications
* Tkae dataframe applications, convert to read stream, and you have a continuous application.



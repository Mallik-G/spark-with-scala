# Spark Intro

## What is spark?

Fast an general engine for large scale data processing!

It provides a mechanism for very simple and very efficiently processing that data.

You can do this on a cluster to run on own desktop.

## Architecture

The high level architecture: 

* We write Driver Programs
    - The spark context contain the encapsulation of the underlying hardware we are using
* Under that is a cluster manager
    - Can use it on top of Hadoop YARN, or mesos
    - It distributes the work requested by driver programme
* The cluster manager will split the work needd into multiple executors
    - Each machine might have a process with own cache and tasks

**All the stuff in the right happens automagically**

You're not totally off the hook on how it gets distributed, but for the most part it just works!

## Why Spark instead of others?

* Why not map reduce?
    - Spark says it can run 100x faster than Hadoop Map Reduce in memory, or 10x on disk
* It uses a Directed Acyclic Graph (DAG) to optimize workflows

In map reduce we would find ourselves writing a lot of code from the ground up!!

We don't actualyl run stuff until we need to collect results, so it is able to optimize the processing to get the end result!

## It's popular!

* Amazon
* Ebay
* NASA
* Groupon
* TripAdviser
* Yahoo
* OTHERS!

## It's not hard

* Code in python, java, scala
* Recommended scala for efficiency
    - Also tidiest code
* Built around one main concept: The resilient distributed dataset (RDD)


# Components of Spark

* Spark CORE
    - Deals with basics
    - Deals with RDDs
    - Reduces them
    - ETC
* There are things built on top
    - Spark Streaming
        + Can handle mini-micro busrsts of data coming in streaming
        + Data coming from website, logs or IoT stuff, etc
    - SparkSQL
        + Can open a SQL interface into massively distributed datasets
    - MLLib
        + Allows to do massive datasets
        + Linear regression
        + Recommend stuff from user behaviour
        + Perform Machine Learning
    - GraphX
        + Not touching about graphs in presentations, etc
        + This is graph theory, graph networks
            * IE social network
            * Provides a framework ot get attributes about the graph
            * As well as preggle that can do anything tothe graph
            * It works in distributed manner
            * Can throuhg massive social networking dataset.

## Why Scala?

* Spark is written is scala!
    - best performance
    - Simplest code to look at
    - Not too much boilerplate to add 
    - Funcional programming good fit for dist processing
    - Gives you fast performance (Scala compiles to java bytecode)
    - Less code & boilerplate stuff than java
    - Pyhton is slow in comparison

* Sparc code looks a LOT like Python code 
    - IN context for a spark jobs







